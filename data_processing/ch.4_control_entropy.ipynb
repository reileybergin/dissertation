{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specs:\n",
    "- Low Back IMU \n",
    "- Sampled at 1125 hz\n",
    "- All runs 5 minutes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom functions ---\n",
    "import functions.file_import_gui as gui\n",
    "import functions.data_prep as prep\n",
    "import functions.custom_plots as plots\n",
    "import functions.low_back_measures as back\n",
    "\n",
    "# For saving files\n",
    "import os\n",
    "\n",
    "# For entropy\n",
    "import nolds\n",
    "\n",
    "# For dataframes ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For plotting ---\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in IMU data files ---\n",
    "\n",
    "# Subject to process\n",
    "sub_id = 'run014'\n",
    "\n",
    "# lowg ---\n",
    "# set directory\n",
    "initialdir = f\"data/five_min_runs/{sub_id}/lowg_1125hz/back\"\n",
    "# bring in csv files with data\n",
    "dfs_lowg_lowg_lowg, keys_list = gui.read_csv_files_gui(initialdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prep ---\n",
    "\n",
    "# lowg ---\n",
    "# crop data for 5 mins (removes extra rows at the beginning so that there are exactly 5 mins of data)\n",
    "prep.crop_df_five_mins(dfs_lowg_lowg_lowg, sample_freq = 1125)\n",
    "# calculate and add resultant column\n",
    "prep.add_resultant_column(dfs_lowg_lowg_lowg, column_x = 'ax_m/s/s', column_y = 'ay_m/s/s', column_z = 'az_m/s/s', name_of_res_column = 'res_m/s/s')\n",
    "# convert accel columns to gs\n",
    "prep.accel_to_gs_columns(dfs_lowg_lowg_lowg)\n",
    "# shift time scale to start at 0\n",
    "prep.shift_time_s_to_zero(dfs_lowg_lowg_lowg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Entropy ---\n",
    "# Method with overlapping window\n",
    "\n",
    "# set window size and overlap\n",
    "window_size = 750\n",
    "overlap = 375  # overlapping window of 50%\n",
    "\n",
    "# initialize dictionary to store sample entropy values for each dataframe\n",
    "sample_entropies = {}\n",
    "\n",
    "# loop through dataframes in dictionary\n",
    "for key, df in dfs_lowg.items():\n",
    "    # get signal column from dataframe\n",
    "    signal = df['res_m/s/s'].values\n",
    "\n",
    "    # initialize list to store sample entropy values for each window\n",
    "    sample_entropy_values = []\n",
    "\n",
    "    # calculate sample entropy for each window\n",
    "    # moves over 375 each time and then ends its window at whearever it started plus 750\n",
    "    for i in range(0, len(signal) - window_size, overlap):\n",
    "        window = signal[i:i+window_size]\n",
    "        sample_entropy = nolds.sampen(window, emb_dim=2, tolerance=0.15)\n",
    "        sample_entropy_values.append(sample_entropy)\n",
    "\n",
    "    # calculate the average sample entropy value for the entire signal\n",
    "    average_sample_entropy = np.mean(sample_entropy_values)\n",
    "\n",
    "    # store the average sample entropy value for this dataframe in the dictionary\n",
    "    sample_entropies[key] = average_sample_entropy\n",
    "\n",
    "# convert the dictionary to a dataframe for easier manipulation and analysis\n",
    "sample_entropies_df = pd.DataFrame.from_dict(\n",
    "    sample_entropies, orient='index', columns=['sample_entropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table to export ---\n",
    "\n",
    "# create the variable_export_df dataframe\n",
    "variable_export_df = pd.DataFrame(\n",
    "    columns=['sub_id', 'run_type', 'sensor', 'variable', 'value'])\n",
    "\n",
    "# loop through each row in the sample_entropies_df dataframe\n",
    "for index, row in sample_entropies_df.iterrows():\n",
    "\n",
    "    # extract the sub_id\n",
    "    sub_id = index.split('_')[0]\n",
    "\n",
    "    # extract the run_type\n",
    "    run_type_parts = index.split('_')[1:-2]\n",
    "    run_type = '_'.join(\n",
    "        [part for part in run_type_parts if not part.isdigit()])\n",
    "\n",
    "    # extract the sensor\n",
    "    sensor = None\n",
    "    for word in index.split('_'):\n",
    "        if len(word) == 5 and word.isdigit():\n",
    "            sensor = word\n",
    "            break\n",
    "\n",
    "    # add a new row to the variable_export_df dataframe\n",
    "    variable_export_df = variable_export_df.append({'sub_id': sub_id,\n",
    "                                                    'run_type': run_type,\n",
    "                                                    'sensor': sensor,\n",
    "                                                    'variable': 'control entropy',\n",
    "                                                    'value': row['sample_entropy']},\n",
    "                                                   ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append rows to Excel Table ---\n",
    "\n",
    "# define the file path\n",
    "file_path = \"data/processed_variables/imu_training_load_variables.xlsx\"\n",
    "\n",
    "# load existing excel file (if it exists) or create a new one (if it does not exist)\n",
    "try:\n",
    "    with pd.ExcelFile(file_path) as xlsx:\n",
    "        df = pd.read_excel(xlsx, sheet_name='variables')\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "# append variable_export_df to the existing data in the excel file\n",
    "df = df.append(variable_export_df, ignore_index=True)\n",
    "\n",
    "# write the updated dataframe to the excel file\n",
    "with pd.ExcelWriter(file_path) as writer:\n",
    "    df.to_excel(writer, sheet_name='variables', index=False)\n",
    "\n",
    "# Print a message to indicate that the file has been saved\n",
    "print(f'{sub_id} saved successfully')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imu_training_load_study-UQqD6JkG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
