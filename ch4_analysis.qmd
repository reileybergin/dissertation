---
title: "Ch.4"
subtitle: "IMU Training Load Study"
date: "`r format(Sys.time(), '%d %B, %Y')`" # today's date
author: "Reiley Bergin"
title-block-banner: "#1B365D"
execute:
  warning: false
  message: false
format: 
  html:
    embed-resources: true
    smooth-scroll: true
    toc: true
    toc-depth: 3
    echo: false
    code-tools: true
    link-external-newwindow: true
editor: visual
---

```{r}
#| label: Packages & Themes

library(tidyverse)
library(readr)
library(lme4)
library(brms)
library(easystats)
library(emmeans)
library(openxlsx)

theme_set(theme_bw())
```

```{r}
#| label: Data Prep

full_dataset <- read_csv("data/ch.4_data.csv") %>%
  
  # Remove the two subjects who did not complete heavy week 
  filter(sub_id != "run007", sub_id != "run008") %>%
  
  # Clean up variable names; lb = low back, tb = tibia
  mutate(
    variable = str_replace_all(variable, c(
      "ax_m/s/s_meanshift_filtered_rms_1125hz_ratio" = "lb_x_rms_ratio",
      "ay_m/s/s_meanshift_filtered_rms_1125hz_ratio" = "lb_y_rms_ratio",
      "az_m/s/s_meanshift_filtered_rms_1125hz_ratio" = "lb_z_rms_ratio", 
      "control entropy" = "lb_control_entropy",
      "res_g_avg_peak_lt_1600hz" = "lt_res_pk_accel_g",
      "res_g_avg_peak_rt_1600hz" = "rt_res_pk_accel_g",
      "res_g_avg_peak_back_1125hz" = "lb_res_pk_accel_g"))) 
  
# Calculate avg for left and right tibia
rt_lt_avg <- full_dataset %>%
  filter(variable %in% c("lt_res_pk_accel_g", "rt_res_pk_accel_g")) %>%
  group_by(sub_id, run_type) %>%
  
  # NOTE: if subject is missing rt or lt then mean is just available value
  summarize(rt_lt_avg_res_pk_accel_g = mean(value, na.rm = TRUE), .groups = 'drop') %>%
  
  mutate(
    variable = "tb_res_pk_accel_g", 
    value = rt_lt_avg_res_pk_accel_g) %>%
  select(sub_id, run_type, variable, value)

# Append the original dataset
full_dataset <- bind_rows(full_dataset, rt_lt_avg) %>%
  filter(!variable %in% c("lt_res_pk_accel_g", "rt_res_pk_accel_g")) %>%
  arrange(sub_id, run_type, variable)

rm(rt_lt_avg)
```

```{r}
#| label: Functions

# Write or append a dataframe to an Excel file as a new sheet
write_or_append_xlsx <- function(dataframe, filename, sheetName, row.names=FALSE) {
  if (file.exists(filename)) {
    wb <- loadWorkbook(filename) # Load the existing workbook
  } else {
    wb <- createWorkbook() # Or create a new one if it doesn't exist
  }
  addWorksheet(wb, sheetName)
  writeData(wb, sheetName, dataframe, rowNames=row.names)
  saveWorkbook(wb, filename, overwrite = TRUE)
}
```

### Coefficient of variation (CV)

The CV was calculated for each subject across the 4 light days. The mean CV for each variable was calculated across subjects.

```{r}
#| label: Calc CoV During Light Week

lt_wk <- full_dataset %>%
  filter(str_starts(run_type, "LD") & run_type != "LD5")

# Calculate mean, sd, and CoV for each subject and variable
lt_wk_stats <- lt_wk %>%
  group_by(sub_id, variable) %>%
  summarize(
    mean = mean(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    cv = sd(value, na.rm = TRUE) / mean(value, na.rm = TRUE), 
    cv_per = round(cv*100, 2)
  ) %>%
  ungroup()

lt_wk_mean_cov <- lt_wk_stats  %>%
  group_by(variable) %>%
  summarize(
    cv = mean(cv, na.rm = TRUE), 
    cv_per = round(cv*100, 2)
  ) %>%
  ungroup() 

lt_wk <- full_dataset %>%
  filter(str_starts(run_type, "LD") & run_type != "LD5")
```

```{r}
#| label: Calc CoV for light day and heavy d1 (what is used as baseline)

# Just wanted to compare this to variation of in light week

two_day <- full_dataset %>%
  filter(run_type %in% c("LD5", "HD1"))

# Calculate mean, sd, and CoV for each subject and variable
two_day_stats <- two_day %>%
  group_by(sub_id, variable) %>%
  summarize(
    mean = mean(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    cv = sd(value, na.rm = TRUE) / mean(value, na.rm = TRUE), 
    cv_per = round(cv*100, 2)
  ) %>%
  ungroup()

two_day_mean_cov <- two_day_stats  %>%
  group_by(variable) %>%
  summarize(
    cv = mean(cv, na.rm = TRUE), 
    cv_per = round(cv*100, 2)
  ) %>%
  ungroup() 
```

```{r}
#| label: Plot Light Week

# variables: tb_res_pk_accel_g, lb_res_pk_accel_g, lb_control_entropy, lb_x_rms_ratio, lb_y_rms_ratio, lb_z_rms_ratio

# NOTE on missing data: no tibia for sub001, no tibia for D4 for sub014

lt_wk  %>%
  filter(variable == "lb_x_rms_ratio") %>%
  ggplot(aes(x = run_type, y = value, group = sub_id)) +
  geom_line(linewidth = 0.75) +
  geom_point(shape = 21,
             size = 2,
             color = "black",
             fill = "white") +
  labs(x = "",
       y = "",
       title = "Light Week",
       subtitle = "") +
  facet_wrap(~sub_id) 
```

### Models

```{r}
#| label: Prep Data for Model

# Calculate average values for LD5 and HD1, and label them as BAS
bas_avg <- full_dataset %>%
  filter(run_type %in% c("LD5", "HD1")) %>%
  group_by(sub_id, variable) %>%
  summarize(mean_value = mean(value, na.rm = TRUE), .groups = 'drop') %>%
  mutate(run_type = "BAS", 
         value = mean_value) %>%
  select(sub_id, run_type, variable, value)

# Append the BAS averages back to the original dataset
model_data <- bind_rows(full_dataset, bas_avg) %>%
  arrange(sub_id, run_type, variable)
rm(bas_avg)

# Remove light days and heavy D1 (part of baseline calc)
model_data <- model_data %>%
  filter(!str_starts(run_type, "LD")& run_type != "HD1")

# Convert sub_id and run_type column values to factors
model_data <- model_data %>%
  mutate(
    run_type = factor(run_type, levels = c("BAS", "HD2", "HD3", "HD4", "HD5")),
    sub_id = factor(sub_id)
  )

# Tables for each variable
df_tb_res_pk_accel <- model_data %>%
  filter(variable == "tb_res_pk_accel_g")
df_lb_res_pk_accel <- model_data %>%
  filter(variable == "lb_res_pk_accel_g")
df_lb_control_entropy <- model_data %>%
  filter(variable == "lb_control_entropy")
df_lb_x_rms_ratio <- model_data %>%
  filter(variable == "lb_x_rms_ratio")
df_lb_y_rms_ratio <- model_data %>%
  filter(variable == "lb_y_rms_ratio")
df_lb_z_rms_ratio <- model_data %>%
  filter(variable == "lb_z_rms_ratio")
```

```{r}
#| label: Plot BAS to D5

# variables: tb_res_pk_accel_g, lb_res_pk_accel_g, lb_control_entropy, lb_x_rms_ratio, lb_y_rms_ratio, lb_z_rms_ratio

# NOTE on missing data: no tibia for sub001, no back D3 sub001, no tibia D2 for sub005

model_data %>%
  filter(variable == "lb_x_rms_ratio") %>%
  ggplot(aes(x = run_type, y = value, group = sub_id)) +
  geom_line(linewidth = 0.75) +
  geom_point(shape = 21,
             size = 2,
             color = "black",
             fill = "white") +
  labs(x = "",
       y = "",
       title = "",
       subtitle = "") +
  facet_wrap(~sub_id) 
```

#### Linear Mixed Model (LMM)

```{r}
#| label: LMMs

lmm_tb_res_pk_accel <- lmer(value ~ run_type + (1|sub_id), data = df_tb_res_pk_accel)
lmm_lb_res_pk_accel <- lmer(value ~ run_type + (1|sub_id), data = df_lb_res_pk_accel)
lmm_lb_control_entropy <- lmer(value ~ run_type + (1|sub_id), data = df_lb_control_entropy)
lmm_lb_x_rms_ratio <- lmer(value ~ run_type + (1|sub_id), data = df_lb_x_rms_ratio)
lmm_lb_y_rms_ratio <- lmer(value ~ run_type + (1|sub_id), data = df_lb_y_rms_ratio)
lmm_lb_z_rms_ratio <- lmer(value ~ run_type + (1|sub_id), data = df_lb_z_rms_ratio)
```

```{r}
#| label: LMM Intercept Variance Plots

lattice::dotplot(ranef(lmm_tb_res_pk_accel, condVar = T))
lattice::dotplot(ranef(lmm_lb_res_pk_accel, condVar = T))
lattice::dotplot(ranef(lmm_lb_control_entropy, condVar = T))
lattice::dotplot(ranef(lmm_lb_x_rms_ratio, condVar = T))
lattice::dotplot(ranef(lmm_lb_y_rms_ratio, condVar = T))
lattice::dotplot(ranef(lmm_lb_z_rms_ratio, condVar = T))
```

#### Bayesian Mixed Model (BMM)

Following Ellis 2022 for setting priors (note: when no priors are specified what Ellis described is what brms does on its own)

-   Improper flat priors were were used for all b coefficients in the model.

-   The priors for standard deviation and sigma were restricted to be non-negative, using a half student-t prior with 3 degrees of freedom, a zero location and a scale parameter that is 2.5 or the median absolute deviation of the response variable of greater than 2.5

Priors for intercepts come from the reliability study. Took the avg and sd using both time points pooled together. However, because I did not calculate control entropy for reliability study I used [Gruber 2021](https://www.frontiersin.org/articles/10.3389/fspor.2021.630975/full).

```{r}
#| label: Fit BMMs

bmm_tb_res_pk_accel <-
  brm(
    value ~ run_type + (1|sub_id),
    data = df_tb_res_pk_accel,
    family = gaussian(),
    prior = prior(normal(9.47, 2.34), class = Intercept, lb=0),
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    refresh = 0)

bmm_lb_res_pk_accel <-
  brm(
    value ~ run_type + (1|sub_id),
    data = df_lb_res_pk_accel,
    family = gaussian(),
    prior = prior(normal(5.40, 2.02), class = Intercept, lb=0),
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    refresh = 0)

bmm_lb_control_entropy <-
  brm(
    value ~ run_type + (1|sub_id),
    data = df_lb_control_entropy,
    family = gaussian(),
    prior = prior(normal(0.618, 0.103), class = Intercept, lb=0),
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    refresh = 0)

bmm_lb_x_rms_ratio <-
  brm(
    value ~ run_type + (1|sub_id),
    data = df_lb_x_rms_ratio,
    family = gaussian(),
    prior = prior(normal(0.41, 0.11), class = Intercept, lb=0, ub=1),
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    refresh = 0)

bmm_lb_y_rms_ratio <-
  brm(
    value ~ run_type + (1|sub_id),
    data = df_lb_y_rms_ratio,
    family = gaussian(),
    prior = prior(normal(0.84, 0.08), class = Intercept, lb=0, ub=1),
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    refresh = 0)

bmm_lb_z_rms_ratio <-
  brm(
    value ~ run_type + (1|sub_id),
    data = df_lb_z_rms_ratio,
    family = gaussian(),
    prior = prior(normal(0.32, 0.06), class = Intercept, lb=0, ub=1),
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    refresh = 0)
```

#### Model Checking

1.  **R-hat ≈ 1.0**: Indicates that the chains have converged to a common distribution. The closer R-hat is to 1.0, the better.

2.  **R-hat ≤ 1.01**: Usually considered acceptable. Values in this range suggest that convergence is likely adequate, and the MCMC samples can be trusted for inference.

3.  **R-hat \> 1.01**: Indicates potential issues with convergence. If R-hat is significantly greater than 1.01, it suggests that the chains have not mixed well, and the MCMC simulation may not have adequately explored the posterior distribution. In such cases, it's advisable to investigate further, which might involve running more iterations, adjusting the model, or improving the tuning of the MCMC algorithm

```{r}
#| label: Rhat Check

model_to_check <- bmm_lb_res_pk_accel
rhat(model_to_check)
```

```{r}
#| label: Posterior Predictive Checks

model_to_check <- bmm_lb_res_pk_accel

pp_check(model_to_check, ndraws = 50)
pp_check(model_to_check, "stat")
pp_check(model_to_check, "stat_grouped", group = "run_type")
```

```{r}
#| label: Leave-One-Out Validation

loo_bmm_tb_res_pk_accel <- loo(bmm_tb_res_pk_accel)
loo_bmm_lb_res_pk_accel <- loo(bmm_lb_res_pk_accel)
loo_bmm_lb_control_entropy <- loo(bmm_lb_control_entropy)

loo_bmm_lb_x_rms_ratio <- loo(bmm_lb_x_rms_ratio)
loo_bmm_lb_y_rms_ratio <- loo(bmm_lb_y_rms_ratio)
loo_bmm_lb_z_rms_ratio <- loo(bmm_lb_z_rms_ratio)
```

#### Estimated Marginal Means & Mean Diff

```{r}
#| label: EMM & Pairs (Mean Diff)

# emm
em_tb_res_pk_accel <- emmeans(bmm_tb_res_pk_accel, ~ run_type, level = 0.89)
em_lb_res_pk_accel <- emmeans(bmm_lb_res_pk_accel, ~ run_type, level = 0.89)
em_lb_control_entropy <- emmeans(bmm_lb_control_entropy, ~ run_type, level = 0.89)
em_lb_x_rms_ratio <- emmeans(bmm_lb_x_rms_ratio, ~ run_type, level = 0.89)
em_lb_y_rms_ratio <- emmeans(bmm_lb_y_rms_ratio, ~ run_type, level = 0.89)
em_lb_z_rms_ratio <- emmeans(bmm_lb_z_rms_ratio, ~ run_type, level = 0.89)

# diff
diff_em_tb_res_pk_accel <- pairs(em_tb_res_pk_accel)
diff_em_lb_res_pk_accel <- pairs(em_lb_res_pk_accel)
diff_em_lb_control_entropy <- pairs(em_lb_control_entropy)
diff_em_lb_x_rms_ratio <- pairs(em_lb_x_rms_ratio)
diff_em_lb_y_rms_ratio <- pairs(em_lb_y_rms_ratio)
diff_em_lb_z_rms_ratio <- pairs(em_lb_z_rms_ratio)
```

#### Probability of Direction (pd)

From [`bayestestR`](https://easystats.github.io/bayestestR/reference/p_direction.html):

This can be interpreted as the probability that a parameter (described by its posterior distribution) is strictly positive or negative (whichever is the most probable). Although differently expressed, this index is fairly similar (i.e., is strongly correlated) to the frequentist p-value.

```{r}
#| label: Probability of Direction (pd)

pd_tb_res_pk_accel <- bayestestR::p_direction(diff_em_tb_res_pk_accel)
pd_lb_res_pk_accel <- bayestestR::p_direction(diff_em_lb_res_pk_accel)
pd_lb_control_entropy <- bayestestR::p_direction(diff_em_lb_control_entropy)

pd_lb_x_rms_ratio <- bayestestR::p_direction(diff_em_lb_x_rms_ratio)
pd_lb_y_rms_ratio <- bayestestR::p_direction(diff_em_lb_y_rms_ratio)
pd_lb_z_rms_ratio <- bayestestR::p_direction(diff_em_lb_z_rms_ratio)
```

#### Practical Significance (ps)

From [`bayestestR`](https://easystats.github.io/bayestestR/reference/p_significance.html#:~:text=p_significance()%20returns%20the%20proportion,value%20being%20outside%20the%20ROPE.)`:`

`p_significance()` returns the proportion of a probability distribution (`x`) that is outside a certain range (the negligible effect, or ROPE, see argument `threshold`). If there are values of the distribution both below and above the ROPE, `p_significance()` returns the higher probability of a value being outside the ROPE. Typically, this value should be larger than 0.5 to indicate practical significance. However, if the range of the negligible effect is rather large compared to the range of the probability distribution `x`, `p_significance()` will be less than 0.5, which indicates no clear practical significance.

```{r}
#| label: CV Thresholds for Each Variable

cv_thres_tb_res_pk_accel <- em_tb_res_pk_accel@bhat[1] * lt_wk_mean_cov %>%
  filter(variable == "tb_res_pk_accel_g") %>%
  pull(cv)

cv_thres_lb_res_pk_accel <- em_lb_res_pk_accel@bhat[1] * lt_wk_mean_cov %>%
  filter(variable == "lb_res_pk_accel_g") %>%
  pull(cv)

cv_thres_lb_control_entropy <- em_lb_control_entropy@bhat[1] * lt_wk_mean_cov %>%
  filter(variable == "lb_control_entropy") %>%
  pull(cv)

cv_thres_lb_x_rms_ratio <- em_lb_x_rms_ratio@bhat[1] * lt_wk_mean_cov %>%
  filter(variable == "lb_x_rms_ratio") %>%
  pull(cv)

cv_thres_lb_y_rms_ratio <- em_lb_y_rms_ratio@bhat[1] * lt_wk_mean_cov %>%
  filter(variable == "lb_y_rms_ratio") %>%
  pull(cv)

cv_thres_lb_z_rms_ratio <- em_lb_z_rms_ratio@bhat[1] * lt_wk_mean_cov %>%
  filter(variable == "lb_z_rms_ratio") %>%
  pull(cv)
```

```{r}
#| label: Practical Significance (ps)

ps_tb_res_pk_accel <- bayestestR::p_significance(diff_em_tb_res_pk_accel, threshold = cv_thres_tb_res_pk_accel) 
ps_lb_res_pk_accel <- bayestestR::p_significance(diff_em_lb_res_pk_accel, threshold = cv_thres_lb_res_pk_accel) 
ps_lb_control_entropy <- bayestestR::p_significance(diff_em_lb_control_entropy, threshold = cv_thres_lb_control_entropy)

ps_lb_x_rms_ratio <- bayestestR::p_significance(diff_em_lb_x_rms_ratio, threshold = cv_thres_lb_x_rms_ratio)
ps_lb_y_rms_ratio <- bayestestR::p_significance(diff_em_lb_y_rms_ratio, threshold = cv_thres_lb_y_rms_ratio)
ps_lb_z_rms_ratio <- bayestestR::p_significance(diff_em_lb_z_rms_ratio, threshold = cv_thres_lb_z_rms_ratio)
```

#### Export Results for Bayes Analysis

```{r}
#| label: Export Results for Bayes Analysis

# tb_res_pk_accel
write_or_append_xlsx(em_tb_res_pk_accel, "ch.4_results/tb_res_pk_accel.xlsx", "emm", FALSE)
write_or_append_xlsx(diff_em_tb_res_pk_accel, "ch.4_results/tb_res_pk_accel.xlsx", "diff", FALSE)
write_or_append_xlsx(pd_tb_res_pk_accel, "ch.4_results/tb_res_pk_accel.xlsx", "p_dir", FALSE)
write_or_append_xlsx(ps_tb_res_pk_accel, "ch.4_results/tb_res_pk_accel.xlsx", "p_prac_sig", FALSE)

# lb_res_pk_accel
write_or_append_xlsx(em_lb_res_pk_accel, "ch.4_results/lb_res_pk_accel.xlsx", "emm", FALSE)
write_or_append_xlsx(diff_em_lb_res_pk_accel, "ch.4_results/lb_res_pk_accel.xlsx", "diff", FALSE)
write_or_append_xlsx(pd_lb_res_pk_accel, "ch.4_results/lb_res_pk_accel.xlsx", "p_dir", FALSE)
write_or_append_xlsx(ps_lb_res_pk_accel, "ch.4_results/lb_res_pk_accel.xlsx", "p_prac_sig", FALSE)

# lb_control_entropy
write_or_append_xlsx(em_lb_control_entropy, "ch.4_results/lb_control_entropy.xlsx", "emm", FALSE)
write_or_append_xlsx(diff_em_lb_control_entropy, "ch.4_results/lb_control_entropy.xlsx", "diff", FALSE)
write_or_append_xlsx(pd_lb_control_entropy, "ch.4_results/lb_control_entropy.xlsx", "p_dir", FALSE)
write_or_append_xlsx(ps_lb_control_entropy, "ch.4_results/lb_control_entropy.xlsx", "p_prac_sig", FALSE)

# lb_x_rms_ratio
write_or_append_xlsx(em_lb_x_rms_ratio, "ch.4_results/lb_x_rms_ratio.xlsx", "emm", FALSE)
write_or_append_xlsx(diff_em_lb_x_rms_ratio, "ch.4_results/lb_x_rms_ratio.xlsx", "diff", FALSE)
write_or_append_xlsx(pd_lb_x_rms_ratio, "ch.4_results/lb_x_rms_ratio.xlsx", "p_dir", FALSE)
write_or_append_xlsx(ps_lb_x_rms_ratio, "ch.4_results/lb_x_rms_ratio.xlsx", "p_prac_sig", FALSE)

# lb_y_rms_ratio
write_or_append_xlsx(em_lb_y_rms_ratio, "ch.4_results/lb_y_rms_ratio.xlsx", "emm", FALSE)
write_or_append_xlsx(diff_em_lb_y_rms_ratio, "ch.4_results/lb_y_rms_ratio.xlsx", "diff", FALSE)
write_or_append_xlsx(pd_lb_y_rms_ratio, "ch.4_results/lb_y_rms_ratio.xlsx", "p_dir", FALSE)
write_or_append_xlsx(ps_lb_y_rms_ratio, "ch.4_results/lb_y_rms_ratio.xlsx", "p_prac_sig", FALSE)

# lb_z_rms_ratio
write_or_append_xlsx(em_lb_z_rms_ratio, "ch.4_results/lb_z_rms_ratio.xlsx", "emm", FALSE)
write_or_append_xlsx(diff_em_lb_z_rms_ratio, "ch.4_results/lb_z_rms_ratio.xlsx", "diff", FALSE)
write_or_append_xlsx(pd_lb_z_rms_ratio, "ch.4_results/lb_z_rms_ratio.xlsx", "p_dir", FALSE)
write_or_append_xlsx(ps_lb_z_rms_ratio, "ch.4_results/lb_z_rms_ratio.xlsx", "p_prac_sig", FALSE)
```

### Individual-Level Analysis

The goal here is to determine if subjects changes outside of their CV.

```{r}
#| label: Percent Change from Baseline

# Calculating percent change relative to BAS
per_chg_from_bas <- model_data %>%
  group_by(sub_id, variable) %>%
  spread(key = run_type, value = value) %>%
  mutate(across(c(HD2, HD3, HD4, HD5), ~(. - BAS) / BAS * 100, .names = "{.col}_per_chg")) %>%
  select(sub_id, variable, ends_with("per_chg")) %>%
  gather(key = "run_type", value = "per_chg", -sub_id, -variable) %>%
  mutate(run_type = str_replace(run_type, "_per_chg", "")) %>%
  mutate(per_chg_abs = abs(per_chg)) %>%
  select(sub_id, run_type, variable, per_chg, per_chg_abs)

# Joing table with light week stats table
per_chg_from_bas <- per_chg_from_bas %>%
  left_join(lt_wk_stats, by = c("sub_id", "variable")) %>%
  select(-all_of(c("mean", "sd", "cv")))

# Determine if change from baseline is outside of CV from light week
per_chg_from_bas <- per_chg_from_bas %>%
    mutate(
    outside_cv = if_else(per_chg_abs > cv_per, 1, 0),
    outside_cov_increase = if_else(per_chg > 0 & per_chg_abs > cv_per, 1, 0), 
    outside_cov_decrease = if_else(per_chg < 0 & per_chg_abs > cv_per, 1, 0)  
  )

# Summary table for counts of variables outside CV
summary_outside_cv <- per_chg_from_bas %>%
  group_by(variable) %>%
  summarize(
    count_outside_cv = sum(outside_cv, na.rm = TRUE),
    count_outside_cv_increase = sum(outside_cov_increase, na.rm = TRUE),
    count_outside_cv_decrease = sum(outside_cov_decrease, na.rm = TRUE)
  )

# Summary table for counts of variables outside CV by run_type
summary_run_type_outside_cv <- per_chg_from_bas %>%
  group_by(variable, run_type) %>%
  summarize(
    count_outside_cv = sum(outside_cv, na.rm = TRUE),
    count_outside_cv_increase = sum(outside_cov_increase, na.rm = TRUE),
    count_outside_cv_decrease = sum(outside_cov_decrease, na.rm = TRUE)
  )
```

#### Export Results for Individual Analysis

```{r}
#| label: Export Results for Individual Analysis

write_or_append_xlsx(per_chg_from_bas, "ch.4_results/indiv_changes.xlsx", "per_chg_from_bas", FALSE)
write_or_append_xlsx(summary_outside_cv, "ch.4_results/indiv_changes.xlsx", "outside_cv", FALSE)
write_or_append_xlsx(summary_run_type_outside_cv, "ch.4_results/indiv_changes.xlsx", "run_type_outside_cv", FALSE)
```
