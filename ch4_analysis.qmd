---
title: "Ch.4"
subtitle: "IMU Training Load Study"
date: "`r format(Sys.time(), '%d %B, %Y')`" # today's date
author: "Reiley Bergin"
title-block-banner: "#1B365D"
execute:
  warning: false
  message: false
format: 
  html:
    embed-resources: true
    smooth-scroll: true
    toc: true
    toc-depth: 3
    echo: false
    code-tools: true
    link-external-newwindow: true
editor: visual
---

```{r}
#| label: Packages & Themes

library(tidyverse)
library(readr)
library(lme4)
library(brms)
library(easystats)
library(emmeans)
library(openxlsx)
library(ggalt)

theme_set(theme_bw())
```

```{r}
#| label: Data Prep

imu_data <- read_csv("data/ch.4_imu_data.csv") %>%
  
  # Remove the two subjects who did not complete heavy week 
  filter(sub_id != "run007", sub_id != "run008") %>%
  
  # Clean up variable names; lb = low back, tb = tibia
  mutate(
    variable = str_replace_all(variable, c(
      "ax_m/s/s_meanshift_filtered_rms_1125hz_ratio" = "lb_x_rms_ratio",
      "ay_m/s/s_meanshift_filtered_rms_1125hz_ratio" = "lb_y_rms_ratio",
      "az_m/s/s_meanshift_filtered_rms_1125hz_ratio" = "lb_z_rms_ratio", 
      "control entropy" = "lb_control_entropy",
      "res_g_avg_peak_lt_1600hz" = "lt_res_pk_accel_g",
      "res_g_avg_peak_rt_1600hz" = "rt_res_pk_accel_g",
      "res_g_avg_peak_back_1125hz" = "lb_res_pk_accel_g"))) 
  
# Calculate avg for left and right tibia
rt_lt_avg <- imu_data %>%
  filter(variable %in% c("lt_res_pk_accel_g", "rt_res_pk_accel_g")) %>%
  group_by(sub_id, run_type) %>%
  
  # NOTE: if subject is missing rt or lt then mean is just available value
  summarize(rt_lt_avg_res_pk_accel_g = mean(value, na.rm = TRUE), .groups = 'drop') %>%
  
  mutate(
    variable = "tb_res_pk_accel_g", 
    value = rt_lt_avg_res_pk_accel_g) %>%
  select(sub_id, run_type, variable, value)

# Append the original dataset
imu_data <- bind_rows(imu_data, rt_lt_avg) %>%
  filter(!variable %in% c("lt_res_pk_accel_g", "rt_res_pk_accel_g")) %>%
  arrange(sub_id, run_type, variable)

rm(rt_lt_avg)
```

```{r}
#| label: Functions

# Write or append a dataframe to an Excel file as a new sheet
write_or_append_xlsx <- function(dataframe, filename, sheetName, row.names=FALSE) {
  if (file.exists(filename)) {
    wb <- loadWorkbook(filename) # Load the existing workbook
  } else {
    wb <- createWorkbook() # Or create a new one if it doesn't exist
  }
  addWorksheet(wb, sheetName)
  writeData(wb, sheetName, dataframe, rowNames=row.names)
  saveWorkbook(wb, filename, overwrite = TRUE)
}
```

### Coefficient of variation (CV)

The CV was calculated for each subject across the 4 light days. The mean CV for each variable was calculated across subjects.

```{r}
#| label: Calc CoV During Light Week

lt_wk <- imu_data %>%
  filter(str_starts(run_type, "LD") & run_type != "LD5")

# Calculate mean, sd, and CoV for each subject and variable
lt_wk_stats <- lt_wk %>%
  group_by(sub_id, variable) %>%
  summarize(
    mean = mean(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    cv = sd(value, na.rm = TRUE) / mean(value, na.rm = TRUE), 
    cv_per = round(cv*100, 2)
  ) %>%
  ungroup()

lt_wk_mean_cov <- lt_wk_stats  %>%
  group_by(variable) %>%
  summarize(
    cv = mean(cv, na.rm = TRUE), 
    cv_per = round(cv*100, 2)
  ) %>%
  ungroup() 

lt_wk <- imu_data %>%
  filter(str_starts(run_type, "LD") & run_type != "LD5")
```

```{r}
#| label: Calc CoV for light day and heavy d1 (what is used as baseline)

# Just wanted to compare this to variation of in light week

two_day <- imu_data %>%
  filter(run_type %in% c("LD5", "HD1"))

# Calculate mean, sd, and CoV for each subject and variable
two_day_stats <- two_day %>%
  group_by(sub_id, variable) %>%
  summarize(
    mean = mean(value, na.rm = TRUE),
    sd = sd(value, na.rm = TRUE),
    cv = sd(value, na.rm = TRUE) / mean(value, na.rm = TRUE), 
    cv_per = round(cv*100, 2)
  ) %>%
  ungroup()

two_day_mean_cov <- two_day_stats  %>%
  group_by(variable) %>%
  summarize(
    cv = mean(cv, na.rm = TRUE), 
    cv_per = round(cv*100, 2)
  ) %>%
  ungroup() 
```

```{r}
#| label: Plot Light Week

# variables: tb_res_pk_accel_g, lb_res_pk_accel_g, lb_control_entropy, lb_x_rms_ratio, lb_y_rms_ratio, lb_z_rms_ratio

# NOTE on missing data: no tibia for sub001, no tibia for D4 for sub014

lt_wk  %>%
  filter(variable == "lb_x_rms_ratio") %>%
  ggplot(aes(x = run_type, y = value, group = sub_id)) +
  geom_line(linewidth = 0.75) +
  geom_point(shape = 21,
             size = 2,
             color = "black",
             fill = "white") +
  labs(x = "",
       y = "",
       title = "Light Week",
       subtitle = "") +
  facet_wrap(~sub_id) 
```

### Models

```{r}
#| label: Prep Data for Model

# Calculate average values for LD5 and HD1, and label them as BAS
bas_avg <- imu_data %>%
  filter(run_type %in% c("LD5", "HD1")) %>%
  group_by(sub_id, variable) %>%
  summarize(mean_value = mean(value, na.rm = TRUE), .groups = 'drop') %>%
  mutate(run_type = "BAS", 
         value = mean_value) %>%
  select(sub_id, run_type, variable, value)

# Append the BAS averages back to the original dataset
model_data <- bind_rows(imu_data, bas_avg) %>%
  arrange(sub_id, run_type, variable)
rm(bas_avg)

# Remove light days and heavy D1 (part of baseline calc)
model_data <- model_data %>%
  filter(!str_starts(run_type, "LD")& run_type != "HD1")

# Convert sub_id and run_type column values to factors
model_data <- model_data %>%
  mutate(
    run_type = factor(run_type, levels = c("BAS", "HD2", "HD3", "HD4", "HD5")),
    sub_id = factor(sub_id)
  )

# Tables for each variable
df_tb_res_pk_accel <- model_data %>%
  filter(variable == "tb_res_pk_accel_g")
df_lb_res_pk_accel <- model_data %>%
  filter(variable == "lb_res_pk_accel_g")
df_lb_control_entropy <- model_data %>%
  filter(variable == "lb_control_entropy")
df_lb_x_rms_ratio <- model_data %>%
  filter(variable == "lb_x_rms_ratio")
df_lb_y_rms_ratio <- model_data %>%
  filter(variable == "lb_y_rms_ratio")
df_lb_z_rms_ratio <- model_data %>%
  filter(variable == "lb_z_rms_ratio")
```

```{r}
#| label: Plot BAS to D5

# variables: tb_res_pk_accel_g, lb_res_pk_accel_g, lb_control_entropy, lb_x_rms_ratio, lb_y_rms_ratio, lb_z_rms_ratio

# NOTE on missing data: no tibia for sub001, no back D3 sub001, no tibia D2 for sub005

variable_to_plot = "tb_res_pk_accel_g"

model_data %>%
  filter(variable == variable_to_plot) %>%
  ggplot(aes(x = run_type, y = value, group = sub_id)) +
  geom_line(linewidth = 0.75) +
  geom_point(shape = 21,
             size = 2,
             color = "black",
             fill = "white") +
  labs(x = "",
       y = "",
       title = variable_to_plot,
       subtitle = "") +
  facet_wrap(~sub_id) 

# Define a custom color palette
custom_palette <- c("#4b92c3", "#ff983e", "#56b356", "#de5253",
                    "#a985ca", "#a3776f", "#e892ce", "#989898",
                    "#c9ca4e", "#45cbd8")


model_data %>%
  filter(variable == variable_to_plot) %>%
  ggplot(aes(x = run_type, y = value, group = sub_id)) +
  geom_line(aes(color = as.factor(sub_id)), size = 1) +
  geom_point(shape = 21, size = 3, aes(fill = as.factor(sub_id))) +
  scale_color_manual(values = custom_palette, name = "Subject ID") +
  scale_fill_manual(values = custom_palette) +
  labs(x = "",
       y = "",
       title = variable_to_plot,
       subtitle = "",
       color = "Subject ID",
       fill = "Subject ID") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

#### Linear Mixed Model (LMM)

```{r}
#| label: LMMs

lmm_tb_res_pk_accel <- lmer(value ~ run_type + (1|sub_id), data = df_tb_res_pk_accel)
lmm_lb_res_pk_accel <- lmer(value ~ run_type + (1|sub_id), data = df_lb_res_pk_accel)
lmm_lb_control_entropy <- lmer(value ~ run_type + (1|sub_id), data = df_lb_control_entropy)
lmm_lb_x_rms_ratio <- lmer(value ~ run_type + (1|sub_id), data = df_lb_x_rms_ratio)
lmm_lb_y_rms_ratio <- lmer(value ~ run_type + (1|sub_id), data = df_lb_y_rms_ratio)
lmm_lb_z_rms_ratio <- lmer(value ~ run_type + (1|sub_id), data = df_lb_z_rms_ratio)
```

```{r}
#| label: LMM Intercept Variance Plots

lattice::dotplot(ranef(lmm_tb_res_pk_accel, condVar = T))
lattice::dotplot(ranef(lmm_lb_res_pk_accel, condVar = T))
lattice::dotplot(ranef(lmm_lb_control_entropy, condVar = T))
lattice::dotplot(ranef(lmm_lb_x_rms_ratio, condVar = T))
lattice::dotplot(ranef(lmm_lb_y_rms_ratio, condVar = T))
lattice::dotplot(ranef(lmm_lb_z_rms_ratio, condVar = T))
```

#### Bayesian Mixed Model (BMM)

Following Ellis 2022 for setting priors (note: when no priors are specified what Ellis described is what brms does on its own)

-   Improper flat priors were were used for all b coefficients in the model.

-   The priors for standard deviation and sigma were restricted to be non-negative, using a half student-t prior with 3 degrees of freedom, a zero location and a scale parameter that is 2.5 or the median absolute deviation of the response variable of greater than 2.5

Priors for intercepts come from the reliability study. Took the avg and sd using both time points pooled together. However, because I did not calculate control entropy for reliability study I used [Gruber 2021](https://www.frontiersin.org/articles/10.3389/fspor.2021.630975/full).

```{r}
#| label: Fit BMMs

bmm_tb_res_pk_accel <-
  brm(
    value ~ run_type + (1|sub_id),
    data = df_tb_res_pk_accel,
    family = gaussian(),
    prior = prior(normal(9.47, 2.34), class = Intercept, lb=0),
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    refresh = 0)

bmm_lb_res_pk_accel <-
  brm(
    value ~ run_type + (1|sub_id),
    data = df_lb_res_pk_accel,
    family = gaussian(),
    prior = prior(normal(5.40, 2.02), class = Intercept, lb=0),
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    refresh = 0)

bmm_lb_control_entropy <-
  brm(
    value ~ run_type + (1|sub_id),
    data = df_lb_control_entropy,
    family = gaussian(),
    prior = prior(normal(0.618, 0.103), class = Intercept, lb=0),
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    refresh = 0)

bmm_lb_x_rms_ratio <-
  brm(
    value ~ run_type + (1|sub_id),
    data = df_lb_x_rms_ratio,
    family = gaussian(),
    prior = prior(normal(0.41, 0.11), class = Intercept, lb=0, ub=1),
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    refresh = 0)

bmm_lb_y_rms_ratio <-
  brm(
    value ~ run_type + (1|sub_id),
    data = df_lb_y_rms_ratio,
    family = gaussian(),
    prior = prior(normal(0.84, 0.08), class = Intercept, lb=0, ub=1),
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    refresh = 0)

bmm_lb_z_rms_ratio <-
  brm(
    value ~ run_type + (1|sub_id),
    data = df_lb_z_rms_ratio,
    family = gaussian(),
    prior = prior(normal(0.32, 0.06), class = Intercept, lb=0, ub=1),
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    refresh = 0)
```

#### Model Checking

1.  **R-hat ≈ 1.0**: Indicates that the chains have converged to a common distribution. The closer R-hat is to 1.0, the better.

2.  **R-hat ≤ 1.01**: Usually considered acceptable. Values in this range suggest that convergence is likely adequate, and the MCMC samples can be trusted for inference.

3.  **R-hat \> 1.01**: Indicates potential issues with convergence. If R-hat is significantly greater than 1.01, it suggests that the chains have not mixed well, and the MCMC simulation may not have adequately explored the posterior distribution. In such cases, it's advisable to investigate further, which might involve running more iterations, adjusting the model, or improving the tuning of the MCMC algorithm

```{r}
#| label: Rhat Check

model_to_check <- bmm_lb_res_pk_accel
rhat(model_to_check)
```

```{r}
#| label: Posterior Predictive Checks

model_to_check <- bmm_lb_res_pk_accel

pp_check(model_to_check, ndraws = 50)
pp_check(model_to_check, "stat")
pp_check(model_to_check, "stat_grouped", group = "run_type")
```

```{r}
#| label: Leave-One-Out Validation

loo_bmm_tb_res_pk_accel <- loo(bmm_tb_res_pk_accel)
loo_bmm_lb_res_pk_accel <- loo(bmm_lb_res_pk_accel)
loo_bmm_lb_control_entropy <- loo(bmm_lb_control_entropy)

loo_bmm_lb_x_rms_ratio <- loo(bmm_lb_x_rms_ratio)
loo_bmm_lb_y_rms_ratio <- loo(bmm_lb_y_rms_ratio)
loo_bmm_lb_z_rms_ratio <- loo(bmm_lb_z_rms_ratio)
```

#### Estimated Marginal Means & Mean Diff

```{r}
#| label: EMM & Pairs (Mean Diff)

# emm
em_tb_res_pk_accel <- emmeans(bmm_tb_res_pk_accel, ~ run_type, level = 0.89)
em_lb_res_pk_accel <- emmeans(bmm_lb_res_pk_accel, ~ run_type, level = 0.89)
em_lb_control_entropy <- emmeans(bmm_lb_control_entropy, ~ run_type, level = 0.89)
em_lb_x_rms_ratio <- emmeans(bmm_lb_x_rms_ratio, ~ run_type, level = 0.89)
em_lb_y_rms_ratio <- emmeans(bmm_lb_y_rms_ratio, ~ run_type, level = 0.89)
em_lb_z_rms_ratio <- emmeans(bmm_lb_z_rms_ratio, ~ run_type, level = 0.89)

# diff
diff_em_tb_res_pk_accel <- pairs(em_tb_res_pk_accel)
diff_em_lb_res_pk_accel <- pairs(em_lb_res_pk_accel)
diff_em_lb_control_entropy <- pairs(em_lb_control_entropy)
diff_em_lb_x_rms_ratio <- pairs(em_lb_x_rms_ratio)
diff_em_lb_y_rms_ratio <- pairs(em_lb_y_rms_ratio)
diff_em_lb_z_rms_ratio <- pairs(em_lb_z_rms_ratio)
```

```{r}
#| label: Plot means over time

plot(estimate_means(bmm_tb_res_pk_accel, at = "run_type", ci = 0.89))
plot(estimate_means(bmm_lb_res_pk_accel, at = "run_type", ci = 0.89))
plot(estimate_means(bmm_lb_control_entropy, at = "run_type", ci = 0.89))
plot(estimate_means(bmm_lb_x_rms_ratio, at = "run_type", ci = 0.89))
plot(estimate_means(bmm_lb_x_rms_ratio, at = "run_type", ci = 0.89))
plot(estimate_means(bmm_lb_x_rms_ratio, at = "run_type", ci = 0.89))
```

```{r}
#| label: Plot diffs

plot(diff_em_tb_res_pk_accel)
plot(diff_em_lb_res_pk_accel)
plot(diff_em_lb_control_entropy)
plot(diff_em_lb_x_rms_ratio)
plot(diff_em_lb_y_rms_ratio)
plot(diff_em_lb_z_rms_ratio)
```

```{r}
#| label: Plot means and diffs

#NOTE: the cone things are the diffs for *each* pairwise comparision

plot(estimate_contrasts(bmm_tb_res_pk_accel,contrast = "run_type"), estimate_means(bmm_tb_res_pk_accel, at = "run_type", ci = 0.89)) + theme_modern()

plot(estimate_contrasts(bmm_lb_res_pk_accel,contrast = "run_type"), estimate_means(bmm_lb_res_pk_accel, at = "run_type", ci = 0.89)) + theme_modern()

plot(estimate_contrasts(bmm_lb_control_entropy,contrast = "run_type"), estimate_means(bmm_lb_control_entropy, at = "run_type", ci = 0.89)) + theme_modern()

plot(estimate_contrasts(bmm_lb_x_rms_ratio,contrast = "run_type"), estimate_means(bmm_lb_x_rms_ratio, at = "run_type", ci = 0.89)) + theme_modern()

plot(estimate_contrasts(bmm_lb_y_rms_ratio,contrast = "run_type"), estimate_means(bmm_lb_y_rms_ratio, at = "run_type", ci = 0.89)) + theme_modern()

plot(estimate_contrasts(bmm_lb_z_rms_ratio,contrast = "run_type"), estimate_means(bmm_lb_z_rms_ratio, at = "run_type", ci = 0.89)) + theme_modern()
```

#### Probability of Direction (pd)

From [`bayestestR`](https://easystats.github.io/bayestestR/reference/p_direction.html):

This can be interpreted as the probability that a parameter (described by its posterior distribution) is strictly positive or negative (whichever is the most probable). In other words, it represents the certainty associated with the most probable direction (positive or negative) of the effect.

Moreover, it is strongly correlated with the frequentist **p*-value, and can thus be used to draw parallels and give some reference to readers non-familiar with Bayesian statistics. A two-sided* p*-value of respectively `.1`, `.05`, `.01` and `.001` correspond approximately to a* pd**\* of 95%, 97.5%, 99.5% and 99.95%.

Thus, for convenience, we suggest the following reference values as an interpretation helpers:

-   *pd* **\<= 95%** \~ *p* \> .1: uncertain

-   *pd* **\> 95%** \~ *p* \< .1: possibly existing

-   *pd* **\> 97%**: likely existing

-   *pd* **\> 99%**: probably existing

-   *pd* **\> 99.9%**: certainly existing

```{r}
#| label: Probability of Direction (pd)

pd_tb_res_pk_accel <- bayestestR::p_direction(diff_em_tb_res_pk_accel)
pd_lb_res_pk_accel <- bayestestR::p_direction(diff_em_lb_res_pk_accel)
pd_lb_control_entropy <- bayestestR::p_direction(diff_em_lb_control_entropy)
pd_lb_x_rms_ratio <- bayestestR::p_direction(diff_em_lb_x_rms_ratio)
pd_lb_y_rms_ratio <- bayestestR::p_direction(diff_em_lb_y_rms_ratio)
pd_lb_z_rms_ratio <- bayestestR::p_direction(diff_em_lb_z_rms_ratio)
```

#### Practical Significance (ps)

From [`bayestestR`](https://easystats.github.io/bayestestR/reference/p_significance.html#:~:text=p_significance()%20returns%20the%20proportion,value%20being%20outside%20the%20ROPE.)`:`

`p_significance()` returns the proportion of a probability distribution (`x`) that is outside a certain range (the negligible effect, or ROPE, see argument `threshold`). If there are values of the distribution both below and above the ROPE, `p_significance()` returns the higher probability of a value being outside the ROPE. Typically, this value should be larger than 0.5 to indicate practical significance. However, if the range of the negligible effect is rather large compared to the range of the probability distribution `x`, `p_significance()` will be less than 0.5, which indicates no clear practical significance.

```{r}
#| label: CV Thresholds for Each Variable

cv_thres_tb_res_pk_accel <- em_tb_res_pk_accel@bhat[1] * lt_wk_mean_cov %>%
  filter(variable == "tb_res_pk_accel_g") %>%
  pull(cv)

cv_thres_lb_res_pk_accel <- em_lb_res_pk_accel@bhat[1] * lt_wk_mean_cov %>%
  filter(variable == "lb_res_pk_accel_g") %>%
  pull(cv)

cv_thres_lb_control_entropy <- em_lb_control_entropy@bhat[1] * lt_wk_mean_cov %>%
  filter(variable == "lb_control_entropy") %>%
  pull(cv)

cv_thres_lb_x_rms_ratio <- em_lb_x_rms_ratio@bhat[1] * lt_wk_mean_cov %>%
  filter(variable == "lb_x_rms_ratio") %>%
  pull(cv)

cv_thres_lb_y_rms_ratio <- em_lb_y_rms_ratio@bhat[1] * lt_wk_mean_cov %>%
  filter(variable == "lb_y_rms_ratio") %>%
  pull(cv)

cv_thres_lb_z_rms_ratio <- em_lb_z_rms_ratio@bhat[1] * lt_wk_mean_cov %>%
  filter(variable == "lb_z_rms_ratio") %>%
  pull(cv)
```

```{r}
#| label: Practical Significance (ps)

ps_tb_res_pk_accel <- bayestestR::p_significance(diff_em_tb_res_pk_accel, threshold = cv_thres_tb_res_pk_accel) 
ps_lb_res_pk_accel <- bayestestR::p_significance(diff_em_lb_res_pk_accel, threshold = cv_thres_lb_res_pk_accel) 
ps_lb_control_entropy <- bayestestR::p_significance(diff_em_lb_control_entropy, threshold = cv_thres_lb_control_entropy)
ps_lb_x_rms_ratio <- bayestestR::p_significance(diff_em_lb_x_rms_ratio, threshold = cv_thres_lb_x_rms_ratio)
ps_lb_y_rms_ratio <- bayestestR::p_significance(diff_em_lb_y_rms_ratio, threshold = cv_thres_lb_y_rms_ratio)
ps_lb_z_rms_ratio <- bayestestR::p_significance(diff_em_lb_z_rms_ratio, threshold = cv_thres_lb_z_rms_ratio)
```

#### Export Results for Bayes Analysis

```{r}
#| label: Export Results for Bayes Analysis

# tb_res_pk_accel
write_or_append_xlsx(em_tb_res_pk_accel, "ch.4_results/tb_res_pk_accel.xlsx", "emm", FALSE)
write_or_append_xlsx(diff_em_tb_res_pk_accel, "ch.4_results/tb_res_pk_accel.xlsx", "diff", FALSE)
write_or_append_xlsx(pd_tb_res_pk_accel, "ch.4_results/tb_res_pk_accel.xlsx", "p_dir", FALSE)
write_or_append_xlsx(ps_tb_res_pk_accel, "ch.4_results/tb_res_pk_accel.xlsx", "p_prac_sig", FALSE)

# lb_res_pk_accel
write_or_append_xlsx(em_lb_res_pk_accel, "ch.4_results/lb_res_pk_accel.xlsx", "emm", FALSE)
write_or_append_xlsx(diff_em_lb_res_pk_accel, "ch.4_results/lb_res_pk_accel.xlsx", "diff", FALSE)
write_or_append_xlsx(pd_lb_res_pk_accel, "ch.4_results/lb_res_pk_accel.xlsx", "p_dir", FALSE)
write_or_append_xlsx(ps_lb_res_pk_accel, "ch.4_results/lb_res_pk_accel.xlsx", "p_prac_sig", FALSE)

# lb_control_entropy
write_or_append_xlsx(em_lb_control_entropy, "ch.4_results/lb_control_entropy.xlsx", "emm", FALSE)
write_or_append_xlsx(diff_em_lb_control_entropy, "ch.4_results/lb_control_entropy.xlsx", "diff", FALSE)
write_or_append_xlsx(pd_lb_control_entropy, "ch.4_results/lb_control_entropy.xlsx", "p_dir", FALSE)
write_or_append_xlsx(ps_lb_control_entropy, "ch.4_results/lb_control_entropy.xlsx", "p_prac_sig", FALSE)

# lb_x_rms_ratio
write_or_append_xlsx(em_lb_x_rms_ratio, "ch.4_results/lb_x_rms_ratio.xlsx", "emm", FALSE)
write_or_append_xlsx(diff_em_lb_x_rms_ratio, "ch.4_results/lb_x_rms_ratio.xlsx", "diff", FALSE)
write_or_append_xlsx(pd_lb_x_rms_ratio, "ch.4_results/lb_x_rms_ratio.xlsx", "p_dir", FALSE)
write_or_append_xlsx(ps_lb_x_rms_ratio, "ch.4_results/lb_x_rms_ratio.xlsx", "p_prac_sig", FALSE)

# lb_y_rms_ratio
write_or_append_xlsx(em_lb_y_rms_ratio, "ch.4_results/lb_y_rms_ratio.xlsx", "emm", FALSE)
write_or_append_xlsx(diff_em_lb_y_rms_ratio, "ch.4_results/lb_y_rms_ratio.xlsx", "diff", FALSE)
write_or_append_xlsx(pd_lb_y_rms_ratio, "ch.4_results/lb_y_rms_ratio.xlsx", "p_dir", FALSE)
write_or_append_xlsx(ps_lb_y_rms_ratio, "ch.4_results/lb_y_rms_ratio.xlsx", "p_prac_sig", FALSE)

# lb_z_rms_ratio
write_or_append_xlsx(em_lb_z_rms_ratio, "ch.4_results/lb_z_rms_ratio.xlsx", "emm", FALSE)
write_or_append_xlsx(diff_em_lb_z_rms_ratio, "ch.4_results/lb_z_rms_ratio.xlsx", "diff", FALSE)
write_or_append_xlsx(pd_lb_z_rms_ratio, "ch.4_results/lb_z_rms_ratio.xlsx", "p_dir", FALSE)
write_or_append_xlsx(ps_lb_z_rms_ratio, "ch.4_results/lb_z_rms_ratio.xlsx", "p_prac_sig", FALSE)
```

### Individual-Level Analysis

The goal here is to determine if subjects changes outside of their CV.

```{r}
#| label: Percent Change from Baseline

# Calculating percent change relative to BAS
per_chg_from_bas <- model_data %>%
  group_by(sub_id, variable) %>%
  spread(key = run_type, value = value) %>%
  mutate(across(c(HD2, HD3, HD4, HD5), ~(. - BAS) / BAS * 100, .names = "{.col}_per_chg")) %>%
  select(sub_id, variable, ends_with("per_chg")) %>%
  gather(key = "run_type", value = "per_chg", -sub_id, -variable) %>%
  mutate(run_type = str_replace(run_type, "_per_chg", "")) %>%
  mutate(per_chg_abs = abs(per_chg)) %>%
  select(sub_id, run_type, variable, per_chg, per_chg_abs)

# Joing table with light week stats table
per_chg_from_bas <- per_chg_from_bas %>%
  left_join(lt_wk_stats, by = c("sub_id", "variable")) %>%
  select(-all_of(c("mean", "sd", "cv")))

# Determine if change from baseline is outside of CV from light week
per_chg_from_bas <- per_chg_from_bas %>%
    mutate(
    outside_cv = if_else(per_chg_abs > cv_per, 1, 0),
    outside_cov_increase = if_else(per_chg > 0 & per_chg_abs > cv_per, 1, 0), 
    outside_cov_decrease = if_else(per_chg < 0 & per_chg_abs > cv_per, 1, 0)  
  )

# Summary table for counts of variables outside CV
summary_outside_cv <- per_chg_from_bas %>%
  group_by(variable) %>%
  summarize(
    count_outside_cv = sum(outside_cv, na.rm = TRUE),
    count_outside_cv_increase = sum(outside_cov_increase, na.rm = TRUE),
    count_outside_cv_decrease = sum(outside_cov_decrease, na.rm = TRUE)
  )

# Summary table for counts of variables outside CV by run_type
summary_run_type_outside_cv <- per_chg_from_bas %>%
  group_by(variable, run_type) %>%
  summarize(
    count_outside_cv = sum(outside_cv, na.rm = TRUE),
    count_outside_cv_increase = sum(outside_cov_increase, na.rm = TRUE),
    count_outside_cv_decrease = sum(outside_cov_decrease, na.rm = TRUE)
  )
```

#### Export Results for Individual Analysis

```{r}
#| label: Export Results for Individual Analysis

write_or_append_xlsx(per_chg_from_bas, "ch.4_results/indiv_changes.xlsx", "per_chg_from_bas", FALSE)
write_or_append_xlsx(summary_outside_cv, "ch.4_results/indiv_changes.xlsx", "outside_cv", FALSE)
write_or_append_xlsx(summary_run_type_outside_cv, "ch.4_results/indiv_changes.xlsx", "run_type_outside_cv", FALSE)
```

### Two Mile Time Trial

Compare time trial times following 4 days of light training load vs 4 days of heavy training load using a paired t-test.

```{r}
#| label: Data Prep 2mileTT

two_mile_times <- read_csv("data/ch.4_two_mile_times.csv") %>%
  select(sub_id, post_light_sec, post_heavy_sec) %>%
  mutate(diff = post_heavy_sec - post_light_sec)
```

```{r}
#| label: PLot 2mileTT

ggplot(two_mile_times, aes(x = post_light_sec, xend = post_heavy_sec, y = sub_id)) +
  geom_dumbbell(size = 2.5, colour = "#5D9EC3", colour_x = "#E69F00", colour_xend = "#56B4E9") +
  labs(x = "Seconds", y = "Sub ID", title = "Post Light vs. Post Heavy 2MileTT") +
  theme_minimal()
```

#### Frequentist Paired T-Test

```{r}
#| label: Compare 2mileTT w/ Freq T-Test 

ttest_two_mile <- t.test(
    x = two_mile_times$post_light_sec,
    y = two_mile_times$post_heavy_sec,
    paired = TRUE)

es_freq_two_mile <- cohens_d(    
    x = two_mile_times$post_light_sec,
    y = two_mile_times$post_heavy_sec,
    paired = TRUE)
```

#### **Bayesian Paried T-Test**

Bayes Factor Interpretation ([Raftery 1995](https://www.jstor.org/stable/271063))

-   **BF = 1** - No evidence

-   **1 \< BF \<= 3** - Weak

-   **3 \< BF \<= 20** - Positive

-   **20 \< BF \<= 150** - Strong

-   **BF \> 150** - Very strong

```{r}
#| label: Compare 2mileTT w/ Bayes T-Test 

bf_ttest_two_mile <- describe_posterior(BayesFactor::ttestBF(
    x = two_mile_times$post_light_sec,
    y = two_mile_times$post_heavy_sec,
    paired = TRUE), ci = 0.89)

es_bayes_two_mile <- effectsize(BayesFactor::ttestBF(
    x = two_mile_times$post_light_sec,
    y = two_mile_times$post_heavy_sec,
    paired = TRUE), type = "d", ci = 0.89)
```

#### Export Results for 2MileTT

```{r}
#| label: Export Results for 2MileTT

write_or_append_xlsx(bf_ttest_two_mile, "ch.4_results/two_mile_tt.xlsx", "bayes_ttest", FALSE)
write_or_append_xlsx(es_bayes_two_mile, "ch.4_results/two_mile_tt.xlsx", "bayes_cohenD", FALSE)
```

### Edwards TRIMP (eTRIMP)

Comapre eTRIMP across the 4 light and 4 heavy days.

```{r}
#| label: Data Prep eTRIMP

etrimp <- read_csv("data/ch.4_etrimp.csv") %>%
  select(sub_id, run_type, etrimp) %>%
  mutate(day_type = if_else(str_starts(run_type, "L"), "light_days", "heavy_days")) %>%
  group_by(sub_id, day_type) %>%
  summarise(mean_etrimp = mean(etrimp, na.rm = TRUE)) %>%
  ungroup() %>%
  pivot_wider(names_from = day_type, values_from = mean_etrimp)
```

```{r}
#| label: Compare eTRIMP w/ Freq T-Test 

ttest_etrimp <- t.test(
    x = etrimp$heavy_days,
    y = etrimp$light_days,
    paired = TRUE)

es_etrimp <- cohens_d(
    x = etrimp$heavy_days,
    y = etrimp$light_days,
    paired = TRUE)

interpret_cohens_d(es_etrimp)
```

```{r}
#| label: Compare eTRIMP w/ Bayes T-Test 

bf_ttest_etrimp <- describe_posterior(BayesFactor::ttestBF(
    x = etrimp$heavy_days,
    y = etrimp$light_days,
    paired = TRUE), ci = 0.89)

es_bayes_etrimp <- effectsize(BayesFactor::ttestBF(
    x = etrimp$heavy_days,
    y = etrimp$light_days,
    paired = TRUE), type = "d", ci = 0.89)

interpret_cohens_d(es_bayes_etrimp)
```

```{r}
#| label: Export Results for eTRIMP

write_or_append_xlsx(etrimp, "ch.4_results/etrimp.xlsx", "data", FALSE)
write_or_append_xlsx(bf_ttest_etrimp, "ch.4_results/etrimp.xlsx", "bayes_ttest", FALSE)
write_or_append_xlsx(es_bayes_etrimp, "ch.4_results/etrimp.xlsx", "bayes_cohenD", FALSE)
```

### RPE

Compare RPE across 4 light days and 4 heavy days

```{r}
#| label: Data Prep RPE

rpe_light_wk <- read_csv("data/ch.4_rpe_light_wk.csv") %>%
  select(sub_id, rpe) %>%
  mutate(week = "light")

rpe_heavy_wk <- read_csv("data/ch.4_rpe_heavy_wk.csv") %>%
  rowwise() %>%
  mutate(rpe = round(mean(c_across(starts_with("rpe")), na.rm = TRUE))) %>%
  ungroup() %>%
  select(sub_id, rpe) %>%
  mutate(week = "heavy")

rpe <- bind_rows(rpe_light_wk, rpe_heavy_wk) %>%
  group_by(sub_id, week) %>%
  summarise(mean_rpe = mean(rpe, na.rm = TRUE)) %>%
  ungroup() %>%
  pivot_wider(names_from = week, values_from = mean_rpe)
```

```{r}
#| label: Compare RPE w/ Freq T-Test 

ttest_rpe <- t.test(
    x = rpe$heavy,
    y = rpe$light,
    paired = TRUE)

es_rpe <- cohens_d(
    x = rpe$heavy,
    y = rpe$light,
    paired = TRUE)

interpret_cohens_d(es_rpe)
```

```{r}
#| label: Compare RPE w/ Bayes T-Test 

bf_ttest_rpe <- describe_posterior(BayesFactor::ttestBF(
    x = rpe$heavy,
    y = rpe$light,
    paired = TRUE), ci = 0.89)

es_bayes_rpe <- effectsize(BayesFactor::ttestBF(
    x = rpe$heavy,
    y = rpe$light,
    paired = TRUE), type = "d", ci = 0.89)

interpret_cohens_d(es_bayes_rpe)
```

```{r}
#| label: Export Results for RPE

write_or_append_xlsx(rpe, "ch.4_results/rpe.xlsx", "data", FALSE)
write_or_append_xlsx(bf_ttest_rpe, "ch.4_results/rpe.xlsx", "bayes_ttest", FALSE)
write_or_append_xlsx(es_bayes_rpe, "ch.4_results/rpe.xlsx", "bayes_cohenD", FALSE)
```

### DALDA

The total score represents the count of "worse than normal" responses for Part A (1-9) and Part B (10 - 34).

```{r}
#| label: Data Prep DALDA

dalda <- read_csv("data/ch.4_dalda.csv") %>%
  select(-Date) %>%
  mutate(week = case_when(
  str_starts(day, "L") ~ "light",
  str_starts(day, "H") ~ "heavy",
    TRUE ~ NA_character_  
  )) %>%
  select(week, everything())

# part A
partA <- dalda %>%
  select(1:3, matches("^[1-9]\\)")) %>%
  pivot_longer(
    cols = -c(1:3), 
    names_to = "question",
    values_to = "response"
  )
  
# part B
partB <- dalda %>%
  select(1:3, matches("^((1[0-9])|(2[0-9])|(3[0-4]))\\)")) %>%
  pivot_longer(
    cols = -c(1:3), 
    names_to = "question",
    values_to = "response"
  )
```

```{r}
#| label: DALDA Group Tables

grouped_partA <- partA %>%
  filter(response == "A) Worse than normal") %>%
  group_by(sub_id, day) %>%
  summarise(count = n(), .groups = 'drop')

grouped_partB <- partB %>%
  filter(response == "A) Worse than normal") %>%
  group_by(sub_id, day) %>%
  summarise(count = n(), .groups = 'drop')
```

```{r}
#| label: DALDA Calculations

partB_light <- partB %>%
  filter(week == "light") %>%
  filter(response == "A) Worse than normal") %>%
  select(-c(week, response))


partB_heavy <- partB %>%
  filter(week == "heavy") %>%
  filter(response == "A) Worse than normal") %>%
  select(-c(week, response))
```

```{r}

library(lubridate)

# Assuming df is your data frame

# Step 1: Convert 'day' into a numeric sequence
df <- partB_light %>%
  mutate(day_num = as.numeric(sub("LD", "", day))) %>%
  arrange(sub_id, question, day_num)

# Step 2: Group by 'sub_id' and 'question', then detect consecutive sequences
df_processed <- df %>%
  group_by(sub_id, question) %>%
  mutate(consecutive = day_num - lag(day_num, default = first(day_num)) == 1) %>%
  group_by(sub_id, question, cumsum(!consecutive)) %>%
  mutate(streak = row_number()) %>%
  ungroup() %>%
  select(-day_num, -consecutive) %>%
  group_by(sub_id, question) %>%
  summarise(max_streak = max(streak), .groups = 'drop')

# Step 3: Filter or arrange as needed to find subjects with 3 or more consecutive days of the same response
df_filtered <- df_processed %>%
  filter(max_streak >= 3)
```

```{r}
# Assuming df is your data frame

# Step 1: Convert 'day' into a numeric sequence
df <- partB_heavy %>%
  mutate(day_num = as.numeric(sub("HD", "", day))) %>%
  arrange(sub_id, question, day_num)

# Step 2: Group by 'sub_id' and 'question', then detect consecutive sequences
df_processed <- df %>%
  group_by(sub_id, question) %>%
  mutate(consecutive = day_num - lag(day_num, default = first(day_num)) == 1) %>%
  group_by(sub_id, question, cumsum(!consecutive)) %>%
  mutate(streak = row_number()) %>%
  ungroup() %>%
  select(-day_num, -consecutive) %>%
  group_by(sub_id, question) %>%
  summarise(max_streak = max(streak), .groups = 'drop')

# Step 3: Filter or arrange as needed to find subjects with 3 or more consecutive days of the same response
df_filtered_2 <- df_processed %>%
  filter(max_streak >= 3)
```
