{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Rate Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edwards eTRIMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edwards TRIMP (eTRIMP) was calculated based on time spent in 5 HR zones and multiplied by a zone specific weighting factor: duration in zone 1 (50%–59% of HRmax) multiplied by 1, duration in zone 2 (60%–69% HRmax) multiplied by 2, duration in zone 3 (70%–79% HRmax) multiplied by 3, duration in zone 4 (80%–89% HRmax) multiplied by 4, and duration in zone 5 (90%–100% HRmax) multiplied by 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions & packages ---\n",
    "import functions.file_import_gui as gui\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in data ---\n",
    "\n",
    "# set directory\n",
    "initialdir = f\"data/polar_hr\"\n",
    "\n",
    "# select csv files with data - heart rate data (4 days light and 4 days heavy)\n",
    "dfs, keys_list = gui.read_csv_files_gui(initialdir)\n",
    "\n",
    "# max heart rate for each subject\n",
    "max_hr_df = pd.read_csv('data/polar_hr/max_hr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Prep ---\n",
    "\n",
    "def prep_hr_data(dfs):\n",
    "    updated_dfs = {}\n",
    "    \n",
    "    for key, df in dfs.items():\n",
    "        # Keep only the 2nd and 3rd columns\n",
    "        df = df.iloc[:, 1:3]\n",
    "        \n",
    "        # Remove the first two rows to get rid of any headers or metadata\n",
    "        df = df.iloc[2:]\n",
    "        \n",
    "        # Set the first row as column names and remove that row\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df.iloc[1:]\n",
    "        \n",
    "        # Reset the DataFrame index to handle the removal correctly\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Directly rename columns to 'time' and 'hr_bpm'\n",
    "        df.columns = ['time', 'hr_bpm']\n",
    "        \n",
    "        # Ensure all rows after \"0:34:00\" in the 'time' column are removed\n",
    "        if \"0:34:00\" in df['time'].values:\n",
    "            cutoff_index = df[df['time'] == \"0:34:00\"].index.max()\n",
    "            df = df.loc[:cutoff_index]\n",
    "\n",
    "        # Remove rows where 'hr_bpm' contains NaN values and count how many were removed\n",
    "        initial_row_count = len(df)\n",
    "        df['hr_bpm'] = pd.to_numeric(df['hr_bpm'], errors='coerce')  # Convert 'hr_bpm' to numeric, errors coerce to NaN\n",
    "        df = df.dropna(subset=['hr_bpm'])  # Drop rows with NaN in 'hr_bpm'\n",
    "        final_row_count = len(df)\n",
    "        rows_removed = initial_row_count - final_row_count\n",
    "\n",
    "        # Update the dictionary with the modified DataFrame\n",
    "        updated_dfs[key] = df\n",
    "\n",
    "        # Only print if rows were actually removed\n",
    "        if rows_removed > 0:\n",
    "            print(f\"For '{key}', {rows_removed} rows were removed due to NaN in 'hr_bpm'.\")\n",
    "    \n",
    "    return updated_dfs\n",
    "\n",
    "dfs_34mins = prep_hr_data(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate eTRIMP ---\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_eTRIMP(dfs_dict, max_hrs_df):\n",
    "    results = []\n",
    "    for key, df in dfs_dict.items():\n",
    "        # Extract subject ID from key (assuming format 'runXXX_...')\n",
    "        subject_id = key.split('_')[0]\n",
    "        \n",
    "        # Find max_hr for this subject in max_hrs_df\n",
    "        max_hr = pd.to_numeric(max_hrs_df.loc[max_hrs_df['sub_id'] == subject_id, 'max_hr']).iloc[0]\n",
    "        \n",
    "        # Calculate the percentage of HRmax for each heart rate reading\n",
    "        per_max_hr = df['hr_bpm'] / max_hr * 100\n",
    "        \n",
    "        # Define HR zones based on max_hr percentages\n",
    "        zone_durations = {\n",
    "            'zone1': ((per_max_hr >= 50) & (per_max_hr <= 59)).sum(),\n",
    "            'zone2': ((per_max_hr >= 60) & (per_max_hr <= 69)).sum(),\n",
    "            'zone3': ((per_max_hr >= 70) & (per_max_hr <= 79)).sum(),\n",
    "            'zone4': ((per_max_hr >= 80) & (per_max_hr <= 89)).sum(),\n",
    "            'zone5': (per_max_hr > 90).sum(),\n",
    "        }\n",
    "        \n",
    "        # Calculate eTRIMP using the duration in each zone\n",
    "        eTRIMP = sum(zone_durations[f'zone{zone}'] * zone for zone, zone in enumerate([1, 2, 3, 4, 5], start=1))\n",
    "        \n",
    "        # Append the result for this DataFrame to the results list\n",
    "        result = {\n",
    "            'key': key,\n",
    "            'max_hr': max_hr,\n",
    "            **zone_durations,\n",
    "            'etrimp': eTRIMP\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "etrimp_df = calculate_eTRIMP(dfs_34mins, max_hr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data ---\n",
    "\n",
    "# Extract 'sub_id' from the 'key' column and insert it at the beginning (position 0)\n",
    "sub_ids = etrimp_df['key'].apply(lambda x: x.split('_')[0])\n",
    "etrimp_df.insert(0, 'sub_id', sub_ids)\n",
    "\n",
    "# Extract 'run_type' from the 'key' column, capitalize it, and insert it at position 1 (after 'sub_id')\n",
    "run_types = etrimp_df['key'].apply(lambda x: '_'.join(x.split('_')[1:])).str.upper()\n",
    "etrimp_df.insert(1, 'run_type', run_types)\n",
    "\n",
    "# Remove the 'key' and 'max hr'\n",
    "etrimp_df.drop(['key', 'max_hr'], axis=1, inplace=True)\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "output_path = 'data/polar_hr/results/etrimp.csv'\n",
    "etrimp_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imu_training_load_study-UQqD6JkG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
